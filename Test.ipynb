{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "78E1-I-CwWhR"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.backends.cudnn as cudnn\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "from torchvision.transforms import v2\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "from PIL import Image\n",
        "from tempfile import TemporaryDirectory\n",
        "import glob\n",
        "import tqdm\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojvdd8ZKAtiN",
        "outputId": "204ae53a-143f-41a0-d133-5c8f7bedbbbe"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oAWfnb6MAtWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SXRm5f9wZiP",
        "outputId": "e567ff19-578d-430e-b198-228e9025dbf8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip gdrive/My\\ Drive/project_data.zip -d ./data"
      ],
      "metadata": {
        "id": "-k_6xnM9wZew"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data_dir, transform=None):\n",
        "        self.data_dir = data_dir\n",
        "        self.transform = transform\n",
        "\n",
        "        self.filepaths = glob.glob(os.path.join(data_dir, '**/*.jpg'), recursive=True)\n",
        "        self.classes = ['real', 'fake']\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.filepaths)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        filepath = self.filepaths[index]\n",
        "\n",
        "        # Extract the class name from the filepath\n",
        "        class_name = self.classes[1] if \"Fake\" in os.path.dirname(os.path.relpath(filepath, data_dir)) else \\\n",
        "        self.classes[0]\n",
        "\n",
        "        # Map the class name to 'real' or 'fake'\n",
        "        class_label = self.classes.index(class_name)\n",
        "\n",
        "        # Load and transform the image\n",
        "        image = Image.open(filepath)\n",
        "\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, class_label"
      ],
      "metadata": {
        "id": "k8_E2F0symUE"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model_ft, data_path):\n",
        "  # Data transform\n",
        "\n",
        "  # Data augmentation and normalization for training\n",
        "  # Just normalization for validation\n",
        "  data_transforms = {\n",
        "      'test': v2.Compose([\n",
        "          v2.Resize(256),\n",
        "          v2.CenterCrop(224),\n",
        "          v2.ToTensor(),\n",
        "          v2.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "      ]),\n",
        "  }\n",
        "  all_data = datasets.ImageFolder(root=data_path,\n",
        "                                    transform=data_transforms['test'],\n",
        "                                    target_transform=None)\n",
        "\n",
        "  test_dataloader = DataLoader(dataset=all_data,\n",
        "                            batch_size=10,\n",
        "                            num_workers=1,\n",
        "                            shuffle=False)\n",
        "  model_ft.to(device)\n",
        "  model_ft.eval()\n",
        "  list_preds = None\n",
        "  list_labels = None\n",
        "\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for inputs, labels in tqdm(test_dataloader):\n",
        "      labels = labels.to(device, dtype=torch.float32)\n",
        "      inputs = inputs.to(device, dtype=torch.float32)\n",
        "\n",
        "      outputs = model_ft(inputs)\n",
        "      _, preds = torch.max(outputs, 1)\n",
        "\n",
        "      if list_preds is not None:\n",
        "        list_preds = torch.hstack((list_preds, preds.cpu()))\n",
        "        list_labels = torch.hstack((list_labels, labels.cpu()))\n",
        "      else:\n",
        "        list_preds = preds.cpu()\n",
        "        list_labels = labels.cpu()\n",
        "\n",
        "\n",
        "  # after you calculate AUC\n",
        "  list_preds = list_preds > 0.5\n",
        "  list_preds = list_preds.long()\n",
        "  list_labels = list_labels.long()\n",
        "\n",
        "  acc = torch.sum(list_preds == list_labels) / len(all_data)\n",
        "\n",
        "\n",
        "  return acc.item()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KgpRJArkwZaO"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PATH_TO_DATA = './data'\n",
        "PATH_TO_MODEL = './resnet50.pt'"
      ],
      "metadata": {
        "id": "lkhXGjGTwZca"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load(PATH_TO_MODEL)\n",
        "\n",
        "acc = test(model, PATH_TO_DATA)\n",
        "\n",
        "print(f'Accuracy : {acc}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "S8XlwdG-2GB7",
        "outputId": "df739b66-1d96-48bf-fcd6-a54f20ae86cd"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/v2/_deprecated.py:43: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-e002fb1e7890>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH_TO_MODEL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPATH_TO_DATA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-17-8bbb109ebec6>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(model_ft, data_path)\u001b[0m\n\u001b[1;32m     20\u001b[0m                             \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                             shuffle=False)\n\u001b[0;32m---> 22\u001b[0;31m   \u001b[0mmodel_ft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m   \u001b[0mmodel_ft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m   \u001b[0mlist_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'collections.OrderedDict' object has no attribute 'to'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ukm03Dih1Ttz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}